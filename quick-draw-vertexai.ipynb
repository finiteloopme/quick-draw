{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Functional Overview\n",
    "\n",
    "### Flow 1 :: Build a ML Model\n",
    "1. Retrieve data for a provided category (drawing)\n",
    "2. Preprocess the data\n",
    "3. Train a ML model to identify (or classify) the drawing\n",
    "4. Evaluate the model (testing)\n",
    "5. This model will be used to predict (or classify) the picture submited by users\n",
    "\n",
    "### Flow 2 :: Retrain (transfer) a model\n",
    "1. User requests a new type of category\n",
    "2. Retrieve data for that category\n",
    "3. Uplift of retrain the **existing** model to identify the new category\n",
    "4. Evaluate the model\n",
    "5. Use the new model to predict drawings submited by the users\n",
    "\n",
    "### Stretch goal :: Deploy a model on mobile\n",
    "\n",
    "# Showback\n",
    "1. Number of container spun up in the background?\n",
    "2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install `kubeflow` components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Jupyter autocompletion\n",
    "!pip install jupyter_contrib_nbextensions\n",
    "!jupyter contrib nbextension install - user\n",
    "from jedi import settings\n",
    "settings.case_insensitive_completion = True\n",
    "\n",
    "USER_FLAG = \"--user\"\n",
    "# Install ai platform and kfp\n",
    "!pip3 install {USER_FLAG} google-cloud-aiplatform==1.3.0 --upgrade\n",
    "!pip3 install {USER_FLAG} kfp --upgrade\n",
    "!pip install google_cloud_pipeline_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import kubeflow and Google AI libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "\n",
    "from kfp.v2 import compiler\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud services enable compute.googleapis.com         \\\n",
    "                       containerregistry.googleapis.com  \\\n",
    "                       aiplatform.googleapis.com  \\\n",
    "                       cloudbuild.googleapis.com \\\n",
    "                       cloudfunctions.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "\n",
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "# Get projet name\n",
    "shell_output=!gcloud config get-value project 2> /dev/null\n",
    "PROJECT_ID=shell_output[0]\n",
    "\n",
    "# Set bucket name\n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-quickdraw-\" + TIMESTAMP\n",
    "\n",
    "BASE_URL_QUICK_DRAW_NUMPY_DS = \"gs://quickdraw_dataset/full/numpy_bitmap/\"\n",
    "# Create bucket\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root_wine/\"\n",
    "PIPELINE_ROOT\n",
    "\n",
    "USER_FLAG = \"--user\"\n",
    "#!gcloud auth login if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the data\n",
    "The Quick Draw Dataset is a collection of 50 million drawings across [345 categories](https://github.com/googlecreativelab/quickdraw-dataset/blob/master/categories.txt).  The characteristics of the data are explained [here](https://github.com/googlecreativelab/quickdraw-dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Copy over the dataset to local bucket only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category param is the name of the category.  \n",
    "\n",
    "def get_category_data(\n",
    "    category: str,\n",
    "    dataset_train: Output[Dataset],\n",
    "    dataset_test: Output[Dataset]\n",
    "):\n",
    "    from numpy as np\n",
    "    #initialize variables \n",
    "    x = np.empty([0, 784])\n",
    "    y = np.empty([0])\n",
    "    class_names = []\n",
    "\n",
    "    all_categories = np.load(\"https://raw.githubusercontent.com/googlecreativelab/quickdraw-dataset/master/categories.txt\")\n",
    "    selected_category = all_categories.indexOf(category)\n",
    "\n",
    "    data = np.load(BASE_URL_QUICK_DRAW_NUMPY_DS + category + \".npy\")\n",
    "    # max_items_per_class = 4000\n",
    "    # data = data[0: max_items_per_class, :]\n",
    "    labels = np.full(data.shape[0], selected_category)\n",
    "\n",
    "    x = np.concatenate((x, data), axis=0)\n",
    "    y = np.append(y, labels)\n",
    "\n",
    "    # class_name, ext = os.path.splitext(os.path.basename(file))\n",
    "    # class_names.append(class_name)\n",
    "\n",
    "    # data = None\n",
    "    # labels = None\n",
    "    \n",
    "    #randomize the dataset \n",
    "    permutation = np.random.permutation(y.shape[0])\n",
    "    x = x[permutation, :]\n",
    "    y = y[permutation]\n",
    "\n",
    "    #separate into training and testing \n",
    "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
    "\n",
    "    x_test = x[0:vfold_size, :]\n",
    "    y_test = y[0:vfold_size]\n",
    "\n",
    "    x_train = x[vfold_size:x.shape[0], :]\n",
    "    y_train = y[vfold_size:y.shape[0]]\n",
    "    return x_train, y_train, x_test, y_test, class_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
